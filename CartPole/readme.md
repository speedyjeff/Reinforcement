## Cart Pole
The canonical example used to train an unsupervised learning model is the Cart Pole problem.  In physics the device is referred to as an [inverted pendulum](https://en.wikipedia.org/wiki/Inverted_pendulum).

![cartpole](https://github.com/speedyjeff/Reinforcement/blob/main/CartPole/media/cartpole.png)

The cart pole is a cart of mass (M) sliding on a track with no fricition, with a pole of length (L) attached at a pivot point with a weight of mass (m) attached at the top.  The naural state of the pole is to fall either to the right or left (under the influence of gravity).  The only inputs to the system are either a constant force applied to the cart from the left or right.  The goal of the learning model is to keep the pole up as long as possible.  A successful run has it up for at least 200 iterations.

Variable | Value
---------|------
M |  1.0
m |  0.1
L |  1.0
F | 10.0
g |  9.8

The exit criteria for the experiment is if the cart moves too far right or left, the angle (Theta) exceeds a particular value, or if the run hits a particular number of iterations.

Criteria | Value
---------|------
X | <-2.4 or >2.4
Theta | <-0.2 radians or >0.2 radians
Count | >500

This experiment used a random model and two learning models.  The learning models used either Q tables or a Neural Network to learn how to keep the pole up.

Not unsurpisingly, the Neural Network had the best overall performance with both percentage of runs that were over the target and for having a higher average count.  Q learning had more consistent training runs, however it did less well in average.

Training both the Q and Neural Networks had a lot of variability due to randomization.  The cart is initialized with random values between [-0.05,0.05], the Neural Network starts with random inputs and, and both train with random choices to start.  

### Random
The Random model chooses either Left or Right, randomly.  Surprisingly, it is able to achieve pretty good coverage of high'ish scores, but not surprisingly is not very good on average.

iterations | max | average | >200
-----------|-----|---------|-----
   10,000  | 124 | 22.33   | 0
  100,000  | 142 | 22.20   | 0
1,000,000  | 163 | 22.26   | 0

```
./CartPoleDriver.exe -alg random -it 1000000
```

### Q
The Q model learns as it plays, getting smarter with every iteration.  In the start the output is largely choosen randomly, and then as it learns it will correctly predict what to do in each situation.

The input for the Q model is normalized to only the sign of the inputs (eg. + or 1).  The full matrix of incoming values is too large and the model was not able to converge on learning in a reasonable amount of time.

iterations | max | average | >200   | Percent of Evaluated
-----------|-----|---------|--------|---------------------
   10,000  | 501 | 73.42   |    444 | 4.44%
  100,000  | 501 | 93.03   |  5,716 | 5.71%
1,000,000  | 501 | 59.32   | 19,333 | 1.93%

```
./CartPoleDriver.exe -alg q -it 1000000
```

### Neural Network
A Neural Network is a complex equation made up of weights and bias'.  The netowrk is trained with examples generated by the random model which hit a particular threshold (>=50).  These inputs are replayed in the model (except for the last choice, which lead to the random's last run).  The iterations are split (80/20) with the first part being all training and the second part using the model to predict.

In practice, this model is very sensitive to being over fit.  I feel that this is likely due to having such a small output domain (2 choices).  Often an over fit model would choose one direction nearly 100% of the time.

Parameter     | Value
--------------|----------
hidden layers | 4,16,16,2
learning rate | 1.0
mini batch    | 100

iterations | w/ model |max  | average | >200   | Percent of Evaluated
-----------|----------|-----|---------|--------|---------------------
   10,000  |   2,000  |  20 |  14.31  |      0 |  0.00% 
  100,000  |  20,000  | 501 | 185.50  |  4,190 | 20.95%
1,000,000  | 200,000  | 260 | 184.85  | 32,270 | 16.13%

```
./CartPoleDriver.exe -alg neural -it 1000000 -nnlearn 1 -nnhidden 16,16
```

The Neural Network offers a feature to specify different initialization strategies for weights and bias'.  These strategies can be helpful when models become overfit.  In this case, a series of 3 runs was done (with the above command) but across the available initialization strategies.  The results highlighted a few patterns.

Sum of >200         | Bias: Uniform -0.5 to 0.5 | Bias: Uniform -0.1 to 0.1 | Bias: Zero | Bias: 0.1 | Bias: 0.01
--------------------|---------------------------|---------------------------|------------|-----------|-----------
Weight: -0.5 to 0.5 | *327,898*                 | *86,348*                  | *239,930*  | *81,313*  | *173,089*
Weight: -1 to 1     | *186,428*                 | 101,701                   | 97,402     | 0         | 0
Weight: Xavier      | *149,613*                 | 5,087                     | 9,166      | 0         | 347,705
Weight: He          | *145,946*                 | 83,471                    | 0          | 171,283   | 157,182
Weight: LeCun       | *110,936*                 | 129,902                   | 27,059     | 181,696   | 24,555

On average, across 3 runs, strategies for weights or bias' that included a Uniform -0.5 to 0.5 yielded stronger results.

A few combinations yielded models that hit the local max for this training (501 successful movements).  These models were:
 * Uniform -0.5 to 0.5 (weight and bias)
 * Xarier (weight) and uniform -0.5 to 0.5 (bias)
 * He (weight) and 0.01 (bias)


